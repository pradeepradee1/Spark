{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de51d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port', '0'). \\\n",
    "config('spark.shuffle.useOldFetchProtocol', 'true'). \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6139f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_schema = \"order_id long , order_date date, customer_id long,order_status string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac70698",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".schema(orders_schema) \\\n",
    ".load(\"/public/trendytech/orders/orders_1gb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42dd083b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0862c58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use itv006277_cachingdemo_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff02e678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.isCached(\"itv006277_cachingdemo_db.itv006277_orders1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04e409d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14482100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create database itv006277_caching_demo_ext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a6bab",
   "metadata": {},
   "source": [
    "### Note: You can use any orders file as path for csv location for creating a table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed532fdc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcd83e3a",
   "metadata": {},
   "source": [
    "Creating External Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a64e3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create table itv006277_caching_demo_ext.itv006277_orders_ext(order_id long, order_date string, customer_id long, order_status string) using csv location '/user/itv006277/orders/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "352efc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+---------------+\n",
      "|order_id|          order_date|customer_id|   order_status|\n",
      "+--------+--------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:...|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:...|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:...|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:...|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:...|      11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:...|       7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:...|       4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:...|       2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:...|       5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:...|       5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:...|        918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:...|       1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:...|       9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:...|       9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:...|       2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:...|       7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:...|       2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:...|       1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:...|       9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:...|       9198|     PROCESSING|\n",
      "+--------+--------------------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from itv006277_caching_demo_ext.itv006277_orders_ext\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97432918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from itv006277_caching_demo_ext.itv006277_orders_ext\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a803ffd",
   "metadata": {},
   "source": [
    "How Do i check the external table ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53912da",
   "metadata": {},
   "source": [
    "Under the  type columns external "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0d6f2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|            order_id|              bigint|   null|\n",
      "|          order_date|              string|   null|\n",
      "|         customer_id|              bigint|   null|\n",
      "|        order_status|              string|   null|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|            Database|itv006277_caching...|       |\n",
      "|               Table|itv006277_orders_ext|       |\n",
      "|               Owner|           itv006277|       |\n",
      "|        Created Time|Wed Nov 01 02:34:...|       |\n",
      "|         Last Access|Wed Dec 31 19:00:...|       |\n",
      "|          Created By|         Spark 2.4.7|       |\n",
      "|                Type|            EXTERNAL|       |\n",
      "|            Provider|                 csv|       |\n",
      "|    Table Properties|[transient_lastDd...|       |\n",
      "|            Location|hdfs://m01.itvers...|       |\n",
      "|       Serde Library|org.apache.hadoop...|       |\n",
      "|         InputFormat|org.apache.hadoop...|       |\n",
      "|        OutputFormat|org.apache.hadoop...|       |\n",
      "|  Storage Properties|[serialization.fo...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe extended itv006277_caching_demo_ext.itv006277_orders_ext\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd23e79e",
   "metadata": {},
   "source": [
    "Creating cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcbfd62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"cache table itv006277_caching_demo_ext.itv006277_orders_ext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd451bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"insert into itv006277_caching_demo_ext.itv006277_orders_ext values(111111, '2023-05-29', 222222, 'BOOKED')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61374df8",
   "metadata": {},
   "source": [
    "Cache will not hit due to we did some changes in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3165793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1001|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from itv006277_caching_demo_ext.itv006277_orders_ext\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec282ba5",
   "metadata": {},
   "source": [
    "How to refresh table ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "403f9a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"refresh table itv006277_caching_demo_ext.itv006277_orders_ext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb02d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.refreshTable(\"itv006277_caching_demo_ext.itv006277_orders_ext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a52d5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1201|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from itv006277_caching_demo_ext.itv006277_orders_ext\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0550db89",
   "metadata": {},
   "source": [
    "When you insert suing insert command then spark will know that the cache is invalidated and in next subsequent use it will refresh it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e195b",
   "metadata": {},
   "source": [
    "but when we add or remove files in backend then spark cannot track it and we have to refresh the table manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1260e43",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
