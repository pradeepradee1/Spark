{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7742e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f54f4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 06:29:39 WARN Utils: Your hostname, ZSCHN01LP0253L resolves to a loopback address: 127.0.1.1; using 192.168.1.5 instead (on interface wlp0s20f3)\n",
      "23/03/23 06:29:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 06:29:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc76877f610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Spark Session (It will executed in the Local Not in the Master Node)\n",
    "spark=SparkSession.builder.master(\"local[*]\").appName(\"demo\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb1d892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EMPLOYEE_ID: integer (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- EMAIL: string (nullable = true)\n",
      " |-- PHONE_NUMBER: string (nullable = true)\n",
      " |-- HIRE_DATE: string (nullable = true)\n",
      " |-- JOB_ID: string (nullable = true)\n",
      " |-- SALARY: integer (nullable = true)\n",
      " |-- COMMISSION_PCT: string (nullable = true)\n",
      " |-- MANAGER_ID: string (nullable = true)\n",
      " |-- DEPARTMENT_ID: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf = spark.read.option(\"header\",True).option(\"inferSchema\",True).csv(\"../Spark-main/employees.csv\")\n",
    "empDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20f8a369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "empDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8762932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|count(salary)|\n",
      "+-------------+\n",
      "|           50|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.select(count(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f58db60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|total_count|\n",
      "+-----------+\n",
      "|         50|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.select(count(\"salary\").alias(\"total_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb188bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max_salary|\n",
      "+----------+\n",
      "|     24000|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.select(max(\"salary\").alias(\"max_salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca2f296f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min_salary|\n",
      "+----------+\n",
      "|      2100|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.select(min(\"salary\").alias(\"min_salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f78828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|avg_salary|\n",
      "+----------+\n",
      "|   6182.32|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.select(avg(\"salary\").alias(\"avg_salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6bae83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum_salary|\n",
      "+----------+\n",
      "|    309116|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.select(sum(\"salary\").alias(\"sum_salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "135c3db0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "grouping expressions sequence is empty, and 'EMPLOYEE_ID' is not an aggregate function. Wrap '(sum(salary) AS sum_salary)' in windowing function(s) or wrap 'EMPLOYEE_ID' in first() (or first_value) if you don't care which value you get.;\nAggregate [EMPLOYEE_ID#17, sum(salary#24) AS sum_salary#139L]\n+- Relation [EMPLOYEE_ID#17,FIRST_NAME#18,LAST_NAME#19,EMAIL#20,PHONE_NUMBER#21,HIRE_DATE#22,JOB_ID#23,SALARY#24,COMMISSION_PCT#25,MANAGER_ID#26,DEPARTMENT_ID#27] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#empdf.select(\"EMPLOYEE_ID\",sum(\"salary\").alias(\"sum_salary\")).show()\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Note : This will not execute \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mempDf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEMPLOYEE_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msalary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum_salary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/workspace_working_Repo/ML/envname/lib/python3.8/site-packages/pyspark/sql/dataframe.py:2023\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m     \u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \n\u001b[1;32m   2005\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;124;03m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2023\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/workspace_working_Repo/ML/envname/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/workspace_working_Repo/ML/envname/lib/python3.8/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: grouping expressions sequence is empty, and 'EMPLOYEE_ID' is not an aggregate function. Wrap '(sum(salary) AS sum_salary)' in windowing function(s) or wrap 'EMPLOYEE_ID' in first() (or first_value) if you don't care which value you get.;\nAggregate [EMPLOYEE_ID#17, sum(salary#24) AS sum_salary#139L]\n+- Relation [EMPLOYEE_ID#17,FIRST_NAME#18,LAST_NAME#19,EMAIL#20,PHONE_NUMBER#21,HIRE_DATE#22,JOB_ID#23,SALARY#24,COMMISSION_PCT#25,MANAGER_ID#26,DEPARTMENT_ID#27] csv\n"
     ]
    }
   ],
   "source": [
    "#empdf.select(\"EMPLOYEE_ID\",sum(\"salary\").alias(\"sum_salary\")).show()\n",
    "#Note : This will not execute \n",
    "empDf.select(\"EMPLOYEE_ID\", sum(\"salary\").alias(\"sum_salary\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d2895",
   "metadata": {},
   "source": [
    "### OrderBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb4a11aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|DEPARTMENT_ID|\n",
      "+-----------+----------+-------------+\n",
      "|        132|        TJ|           50|\n",
      "|        136|     Hazel|           50|\n",
      "|        128|    Steven|           50|\n",
      "|        127|     James|           50|\n",
      "|        135|        Ki|           50|\n",
      "|        131|     James|           50|\n",
      "|        119|     Karen|           30|\n",
      "|        140|    Joshua|           50|\n",
      "|        198|    Donald|           50|\n",
      "|        199|   Douglas|           50|\n",
      "|        118|       Guy|           30|\n",
      "|        126|     Irene|           50|\n",
      "|        139|      John|           50|\n",
      "|        130|     Mozhe|           50|\n",
      "|        117|     Sigal|           30|\n",
      "|        116|    Shelli|           30|\n",
      "|        134|   Michael|           50|\n",
      "|        115| Alexander|           30|\n",
      "|        125|     Julia|           50|\n",
      "|        138|   Stephen|           50|\n",
      "+-----------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.select(\"EMPLOYEE_ID\",\"FIRST_NAME\",\"DEPARTMENT_ID\").orderBy(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6b21852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-------------+------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|DEPARTMENT_ID|SALARY|\n",
      "+-----------+----------+-------------+------+\n",
      "|        132|        TJ|           50|  2100|\n",
      "|        136|     Hazel|           50|  2200|\n",
      "|        128|    Steven|           50|  2200|\n",
      "|        127|     James|           50|  2400|\n",
      "|        135|        Ki|           50|  2400|\n",
      "|        131|     James|           50|  2500|\n",
      "|        119|     Karen|           30|  2500|\n",
      "|        140|    Joshua|           50|  2500|\n",
      "|        198|    Donald|           50|  2600|\n",
      "|        199|   Douglas|           50|  2600|\n",
      "|        118|       Guy|           30|  2600|\n",
      "|        126|     Irene|           50|  2700|\n",
      "|        139|      John|           50|  2700|\n",
      "|        130|     Mozhe|           50|  2800|\n",
      "|        117|     Sigal|           30|  2800|\n",
      "|        116|    Shelli|           30|  2900|\n",
      "|        134|   Michael|           50|  2900|\n",
      "|        115| Alexander|           30|  3100|\n",
      "|        125|     Julia|           50|  3200|\n",
      "|        138|   Stephen|           50|  3200|\n",
      "+-----------+----------+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.select(\"EMPLOYEE_ID\",\"FIRST_NAME\",\"DEPARTMENT_ID\",\"SALARY\").orderBy(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4d35a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------+------+\n",
      "|EMPLOYEE_ID| FIRST_NAME|DEPARTMENT_ID|SALARY|\n",
      "+-----------+-----------+-------------+------+\n",
      "|        200|   Jennifer|           10|  4400|\n",
      "|        201|    Michael|           20| 13000|\n",
      "|        202|        Pat|           20|  6000|\n",
      "|        114|        Den|           30| 11000|\n",
      "|        115|  Alexander|           30|  3100|\n",
      "|        116|     Shelli|           30|  2900|\n",
      "|        117|      Sigal|           30|  2800|\n",
      "|        118|        Guy|           30|  2600|\n",
      "|        119|      Karen|           30|  2500|\n",
      "|        203|      Susan|           40|  6500|\n",
      "|        121|       Adam|           50|  8200|\n",
      "|        120|    Matthew|           50|  8000|\n",
      "|        122|      Payam|           50|  7900|\n",
      "|        123|     Shanta|           50|  6500|\n",
      "|        124|      Kevin|           50|  5800|\n",
      "|        137|     Renske|           50|  3600|\n",
      "|        133|      Jason|           50|  3300|\n",
      "|        129|      Laura|           50|  3300|\n",
      "|        125|      Julia|           50|  3200|\n",
      "|        138|    Stephen|           50|  3200|\n",
      "|        134|    Michael|           50|  2900|\n",
      "|        130|      Mozhe|           50|  2800|\n",
      "|        126|      Irene|           50|  2700|\n",
      "|        139|       John|           50|  2700|\n",
      "|        198|     Donald|           50|  2600|\n",
      "|        199|    Douglas|           50|  2600|\n",
      "|        131|      James|           50|  2500|\n",
      "|        140|     Joshua|           50|  2500|\n",
      "|        135|         Ki|           50|  2400|\n",
      "|        127|      James|           50|  2400|\n",
      "|        128|     Steven|           50|  2200|\n",
      "|        136|      Hazel|           50|  2200|\n",
      "|        132|         TJ|           50|  2100|\n",
      "|        103|  Alexander|           60|  9000|\n",
      "|        104|      Bruce|           60|  6000|\n",
      "|        105|      David|           60|  4800|\n",
      "|        106|      Valli|           60|  4800|\n",
      "|        107|      Diana|           60|  4200|\n",
      "|        204|    Hermann|           70| 10000|\n",
      "|        100|     Steven|           90| 24000|\n",
      "|        102|        Lex|           90| 17000|\n",
      "|        101|      Neena|           90| 17000|\n",
      "|        108|      Nancy|          100| 12008|\n",
      "|        109|     Daniel|          100|  9000|\n",
      "|        110|       John|          100|  8200|\n",
      "|        112|Jose Manuel|          100|  7800|\n",
      "|        111|     Ismael|          100|  7700|\n",
      "|        113|       Luis|          100|  6900|\n",
      "|        205|    Shelley|          110| 12008|\n",
      "|        206|    William|          110|  8300|\n",
      "+-----------+-----------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.select(\"EMPLOYEE_ID\",\"FIRST_NAME\",\"DEPARTMENT_ID\",\"SALARY\").orderBy(col(\"DEPARTMENT_ID\").asc(),col(\"SALARY\").desc()).show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d851f",
   "metadata": {},
   "source": [
    "### Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36b5b3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|DEPARTMENT_ID|sum(SALARY)|\n",
      "+-------------+-----------+\n",
      "|           20|      19000|\n",
      "|           40|       6500|\n",
      "|          100|      51608|\n",
      "|           10|       4400|\n",
      "|           50|      85600|\n",
      "|           70|      10000|\n",
      "|           90|      58000|\n",
      "|           60|      28800|\n",
      "|          110|      20308|\n",
      "|           30|      24900|\n",
      "+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.groupBy(\"DEPARTMENT_ID\").sum(\"SALARY\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6420ef8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|DEPARTMENT_ID|max(SALARY)|\n",
      "+-------------+-----------+\n",
      "|           20|      13000|\n",
      "|           40|       6500|\n",
      "|          100|      12008|\n",
      "|           10|       4400|\n",
      "|           50|       8200|\n",
      "|           70|      10000|\n",
      "|           90|      24000|\n",
      "|           60|       9000|\n",
      "|          110|      12008|\n",
      "|           30|      11000|\n",
      "+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.groupBy(\"DEPARTMENT_ID\").max(\"SALARY\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0aeef8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|DEPARTMENT_ID|min(SALARY)|\n",
      "+-------------+-----------+\n",
      "|           20|       6000|\n",
      "|           40|       6500|\n",
      "|          100|       6900|\n",
      "|           10|       4400|\n",
      "|           50|       2100|\n",
      "|           70|      10000|\n",
      "|           90|      17000|\n",
      "|           60|       4200|\n",
      "|          110|       8300|\n",
      "|           30|       2500|\n",
      "+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.groupBy(\"DEPARTMENT_ID\").min(\"SALARY\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d65088ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----------+\n",
      "|DEPARTMENT_ID|    JOB_ID|sum(SALARY)|\n",
      "+-------------+----------+-----------+\n",
      "|           90|   AD_PRES|      24000|\n",
      "|           30|    PU_MAN|      11000|\n",
      "|           70|    PR_REP|      10000|\n",
      "|           50|    ST_MAN|      36400|\n",
      "|           40|    HR_REP|       6500|\n",
      "|           60|   IT_PROG|      28800|\n",
      "|           10|   AD_ASST|       4400|\n",
      "|           30|  PU_CLERK|      13900|\n",
      "|           50|  ST_CLERK|      44000|\n",
      "|           20|    MK_REP|       6000|\n",
      "|           50|  SH_CLERK|       5200|\n",
      "|           90|     AD_VP|      34000|\n",
      "|          100|FI_ACCOUNT|      39600|\n",
      "|          110|    AC_MGR|      12008|\n",
      "|          110|AC_ACCOUNT|       8300|\n",
      "|           20|    MK_MAN|      13000|\n",
      "|          100|    FI_MGR|      12008|\n",
      "+-------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.groupBy(\"DEPARTMENT_ID\",\"JOB_ID\").sum(\"SALARY\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5919dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EMPLOYEE_ID: integer (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- EMAIL: string (nullable = true)\n",
      " |-- PHONE_NUMBER: string (nullable = true)\n",
      " |-- HIRE_DATE: string (nullable = true)\n",
      " |-- JOB_ID: string (nullable = true)\n",
      " |-- SALARY: integer (nullable = true)\n",
      " |-- COMMISSION_PCT: string (nullable = true)\n",
      " |-- MANAGER_ID: string (nullable = true)\n",
      " |-- DEPARTMENT_ID: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a7815b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----------+----------------+\n",
      "|DEPARTMENT_ID|    JOB_ID|sum(SALARY)|sum(EMPLOYEE_ID)|\n",
      "+-------------+----------+-----------+----------------+\n",
      "|           90|   AD_PRES|      24000|             100|\n",
      "|           30|    PU_MAN|      11000|             114|\n",
      "|           70|    PR_REP|      10000|             204|\n",
      "|           50|    ST_MAN|      36400|             610|\n",
      "|           40|    HR_REP|       6500|             203|\n",
      "|           60|   IT_PROG|      28800|             525|\n",
      "|           10|   AD_ASST|       4400|             200|\n",
      "|           30|  PU_CLERK|      13900|             585|\n",
      "|           50|  ST_CLERK|      44000|            2120|\n",
      "|           20|    MK_REP|       6000|             202|\n",
      "|           50|  SH_CLERK|       5200|             397|\n",
      "|           90|     AD_VP|      34000|             203|\n",
      "|          100|FI_ACCOUNT|      39600|             555|\n",
      "|          110|    AC_MGR|      12008|             205|\n",
      "|          110|AC_ACCOUNT|       8300|             206|\n",
      "|           20|    MK_MAN|      13000|             201|\n",
      "|          100|    FI_MGR|      12008|             108|\n",
      "+-------------+----------+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.groupBy(\"DEPARTMENT_ID\",\"JOB_ID\").sum(\"SALARY\", \"EMPLOYEE_ID\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46eb23ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----------+----------+------------------+\n",
      "|DEPARTMENT_ID|SUM_SALARY|MAX_SALARY|MIN_SALARY|        AVG_SALARY|\n",
      "+-------------+----------+----------+----------+------------------+\n",
      "|           20|     19000|     13000|      6000|            9500.0|\n",
      "|           40|      6500|      6500|      6500|            6500.0|\n",
      "|          100|     51608|     12008|      6900| 8601.333333333334|\n",
      "|           10|      4400|      4400|      4400|            4400.0|\n",
      "|           50|     85600|      8200|      2100|3721.7391304347825|\n",
      "|           70|     10000|     10000|     10000|           10000.0|\n",
      "|           90|     58000|     24000|     17000|19333.333333333332|\n",
      "|           60|     28800|      9000|      4200|            5760.0|\n",
      "|          110|     20308|     12008|      8300|           10154.0|\n",
      "|           30|     24900|     11000|      2500|            4150.0|\n",
      "+-------------+----------+----------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.groupBy(\"DEPARTMENT_ID\").agg(sum(\"SALARY\").alias(\"SUM_SALARY\") , max(\"SALARY\").alias(\"MAX_SALARY\"), min(\"SALARY\").alias(\"MIN_SALARY\") , avg(\"SALARY\").alias(\"AVG_SALARY\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71f74167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----------+----------+------------------+\n",
      "|DEPARTMENT_ID|SUM_SALARY|MAX_SALARY|MIN_SALARY|        AVG_SALARY|\n",
      "+-------------+----------+----------+----------+------------------+\n",
      "|           20|     19000|     13000|      6000|            9500.0|\n",
      "|          100|     51608|     12008|      6900| 8601.333333333334|\n",
      "|           70|     10000|     10000|     10000|           10000.0|\n",
      "|           90|     58000|     24000|     17000|19333.333333333332|\n",
      "|          110|     20308|     12008|      8300|           10154.0|\n",
      "|           30|     24900|     11000|      2500|            4150.0|\n",
      "+-------------+----------+----------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.groupBy(\"DEPARTMENT_ID\").agg(sum(\"SALARY\").alias(\"SUM_SALARY\") , max(\"SALARY\").alias(\"MAX_SALARY\"), min(\"SALARY\").alias(\"MIN_SALARY\") , avg(\"SALARY\").alias(\"AVG_SALARY\")).where(col(\"MAX_SALARY\") >= 10000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fdd64f",
   "metadata": {},
   "source": [
    "### Case statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe76c240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+\n",
      "|EMPLOYEE_ID|SALARY|EMP_GRADE|\n",
      "+-----------+------+---------+\n",
      "|        198|  2600|        C|\n",
      "|        199|  2600|        C|\n",
      "|        200|  4400|        C|\n",
      "|        201| 13000|        B|\n",
      "|        202|  6000|        C|\n",
      "|        203|  6500|        C|\n",
      "|        204| 10000|        B|\n",
      "|        205| 12008|        B|\n",
      "|        206|  8300|        C|\n",
      "|        100| 24000|        A|\n",
      "|        101| 17000|        A|\n",
      "|        102| 17000|        A|\n",
      "|        103|  9000|        C|\n",
      "|        104|  6000|        C|\n",
      "|        105|  4800|        C|\n",
      "|        106|  4800|        C|\n",
      "|        107|  4200|        C|\n",
      "|        108| 12008|        B|\n",
      "|        109|  9000|        C|\n",
      "|        110|  8200|        C|\n",
      "|        111|  7700|        C|\n",
      "|        112|  7800|        C|\n",
      "|        113|  6900|        C|\n",
      "|        114| 11000|        B|\n",
      "|        115|  3100|        C|\n",
      "|        116|  2900|        C|\n",
      "|        117|  2800|        C|\n",
      "|        118|  2600|        C|\n",
      "|        119|  2500|        C|\n",
      "|        120|  8000|        C|\n",
      "|        121|  8200|        C|\n",
      "|        122|  7900|        C|\n",
      "|        123|  6500|        C|\n",
      "|        124|  5800|        C|\n",
      "|        125|  3200|        C|\n",
      "|        126|  2700|        C|\n",
      "|        127|  2400|        C|\n",
      "|        128|  2200|        C|\n",
      "|        129|  3300|        C|\n",
      "|        130|  2800|        C|\n",
      "|        131|  2500|        C|\n",
      "|        132|  2100|        C|\n",
      "|        133|  3300|        C|\n",
      "|        134|  2900|        C|\n",
      "|        135|  2400|        C|\n",
      "|        136|  2200|        C|\n",
      "|        137|  3600|        C|\n",
      "|        138|  3200|        C|\n",
      "|        139|  2700|        C|\n",
      "|        140|  2500|        C|\n",
      "+-----------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = empDf.withColumn(\"EMP_GRADE\", when( col(\"SALARY\") > 15000 , \"A\").when( (col(\"SALARY\") >= 10000) & ( col(\"SALARY\") < 15000), \"B\").otherwise(\"C\"))\n",
    "df.select(\"EMPLOYEE_ID\", \"SALARY\", \"EMP_GRADE\").show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233cabbf",
   "metadata": {},
   "source": [
    "### Spark DataFrame to SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70bdd751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|  JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|SH_CLERK|  2600|            - |       124|           50|\n",
      "|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|SH_CLERK|  2600|            - |       124|           50|\n",
      "|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03| AD_ASST|  4400|            - |       101|           10|\n",
      "|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|  MK_MAN| 13000|            - |       100|           20|\n",
      "|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|  MK_REP|  6000|            - |       201|           20|\n",
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Note : Converting Dataframe to SQL type table\n",
    "empDf.createOrReplaceTempView(\"employee\")\n",
    "spark.sql(\" select * from employee limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f27975cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|employee_id|salary|\n",
      "+-----------+------+\n",
      "|        198|  2600|\n",
      "|        199|  2600|\n",
      "|        200|  4400|\n",
      "|        201| 13000|\n",
      "|        202|  6000|\n",
      "|        203|  6500|\n",
      "|        204| 10000|\n",
      "|        205| 12008|\n",
      "|        206|  8300|\n",
      "|        100| 24000|\n",
      "|        101| 17000|\n",
      "|        102| 17000|\n",
      "|        103|  9000|\n",
      "|        104|  6000|\n",
      "|        105|  4800|\n",
      "|        106|  4800|\n",
      "|        107|  4200|\n",
      "|        108| 12008|\n",
      "|        109|  9000|\n",
      "|        110|  8200|\n",
      "|        111|  7700|\n",
      "|        112|  7800|\n",
      "|        113|  6900|\n",
      "|        114| 11000|\n",
      "|        115|  3100|\n",
      "|        116|  2900|\n",
      "|        117|  2800|\n",
      "|        118|  2600|\n",
      "|        119|  2500|\n",
      "|        120|  8000|\n",
      "|        121|  8200|\n",
      "|        122|  7900|\n",
      "|        123|  6500|\n",
      "|        124|  5800|\n",
      "|        125|  3200|\n",
      "|        126|  2700|\n",
      "|        127|  2400|\n",
      "|        128|  2200|\n",
      "|        129|  3300|\n",
      "|        130|  2800|\n",
      "|        131|  2500|\n",
      "|        132|  2100|\n",
      "|        133|  3300|\n",
      "|        134|  2900|\n",
      "|        135|  2400|\n",
      "|        136|  2200|\n",
      "|        137|  3600|\n",
      "|        138|  3200|\n",
      "|        139|  2700|\n",
      "|        140|  2500|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\" select employee_id,salary from employee\")\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0924ed3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|department_id|sum_salary|\n",
      "+-------------+----------+\n",
      "|           20|     19000|\n",
      "|           40|      6500|\n",
      "|          100|     51608|\n",
      "|           10|      4400|\n",
      "|           50|     85600|\n",
      "|           70|     10000|\n",
      "|           90|     58000|\n",
      "|           60|     28800|\n",
      "|          110|     20308|\n",
      "|           30|     24900|\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select department_id, sum(salary) as sum_salary from employee group by department_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01812b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+\n",
      "|employee_id|department_id|rank_salary|\n",
      "+-----------+-------------+-----------+\n",
      "|        200|           10|          1|\n",
      "|        201|           20|          1|\n",
      "|        202|           20|          2|\n",
      "|        114|           30|          1|\n",
      "|        115|           30|          2|\n",
      "|        116|           30|          3|\n",
      "|        117|           30|          4|\n",
      "|        118|           30|          5|\n",
      "|        119|           30|          6|\n",
      "|        203|           40|          1|\n",
      "|        121|           50|          1|\n",
      "|        120|           50|          2|\n",
      "|        122|           50|          3|\n",
      "|        123|           50|          4|\n",
      "|        124|           50|          5|\n",
      "|        137|           50|          6|\n",
      "|        129|           50|          7|\n",
      "|        133|           50|          7|\n",
      "|        125|           50|          9|\n",
      "|        138|           50|          9|\n",
      "+-----------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select employee_id, department_id, rank() over(partition by department_id order by salary desc) as rank_salary from employee\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a1f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287739d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
