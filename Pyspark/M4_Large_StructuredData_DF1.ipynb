{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jscGogpKc47",
        "outputId": "754c4f2f-7dcb-473a-ea4d-d27421eeed68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=94e3bf173c761a7e4abe822eedf49d4f7f0d65701b0bdb998d678e8e52d6a6eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "SMuMiRVyKgpY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.master(\"local[*]\").appName(\"clustername\").getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "0kUqPvvmKkYv",
        "outputId": "ba6159e6-6307-4f3c-f331-969c5573f57d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ee67b130ca0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3b41f922dd08:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>App</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.text(\"/kddcup.data.gz.zip\")\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SXM84ZIQl4O",
        "outputId": "ba47f7fd-370b-44da-f4b2-a3afb1793057"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- value: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "wykPADzMP1DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMe9paq8RhB9",
        "outputId": "514f3882-dac6-4a0e-dbc9-700772d71764"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|       value|\n",
            "+------------+\n",
            "|PK\u0003\u0004-\u0000\u0000\u0000\\b\u0000i|\n",
            "+------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "-W9sMRVUP1lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split\n",
        "split_col = split(df[\"value\"],\",\")\n",
        "df=df.withColumn(\"Protocal\",split_col.getItem(1)) \\\n",
        "      .withColumn(\"Service\",split_col.getItem(2)) \\\n",
        "      .withColumn(\"flag\",split_col.getItem(3)) \\\n",
        "      .withColumn(\"src_bytes\",split_col.getItem(4)) \\\n",
        "      .withColumn(\"dst_bytes\",split_col.getItem(5)) \\\n",
        "      .withColumn(\"urgent\",split_col.getItem(8)) \\\n",
        "      .withColumn(\"num_failed_logins\",split_col.getItem(10)) \\\n",
        "      .withColumn(\"root_shell\",split_col.getItem(13)) \\\n",
        "      .withColumn(\"guest_login\",split_col.getItem(21)) \\\n",
        "      .withColumn(\"label\",split_col.getItem(41)) \\\n",
        "      .drop('value')\n",
        "df.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKFbwsUYRsIA",
        "outputId": "4af7ec9b-4900-4f9b-b1e4-87648e8ad421"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----+---------+---------+------+-----------------+----------+-----------+-----+\n",
            "|Protocal|Service|flag|src_bytes|dst_bytes|urgent|num_failed_logins|root_shell|guest_login|label|\n",
            "+--------+-------+----+---------+---------+------+-----------------+----------+-----------+-----+\n",
            "|    NULL|   NULL|NULL|     NULL|     NULL|  NULL|             NULL|      NULL|       NULL| NULL|\n",
            "+--------+-------+----+---------+---------+------+-----------------+----------+-----------+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.repartition(10)\n",
        "print(df.rdd.getNumPartitions())\n",
        "df.createOrReplaceTempView(\"df_KDDCup\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CR05d_8RsRX",
        "outputId": "a0466362-bc30-4709-fe3c-d0286a1074df"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7kNcBYY2RsTc"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions 1\n",
        "Count the number of connection for each labels"
      ],
      "metadata": {
        "id": "Th0LK_bDU2XV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy('label').count().orderBy('count',ascending=False).show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUwMzOpvRsVL",
        "outputId": "4fd06488-77b5-4a31-adc6-3fc23990dd82"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+\n",
            "|label| count|\n",
            "+-----+------+\n",
            "| NULL|744836|\n",
            "+-----+------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7F16sub-RsXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions 2\n",
        "Get the list of Protocols that are normal and vulnerable to attacks, where there is not guest login to the destination address"
      ],
      "metadata": {
        "id": "uYvKR8NfU6zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sql_query = \"\"\"\n",
        "select Protocal,\n",
        "case\n",
        "when label = 'normal' then 'no attack'\n",
        "else 'attack'\n",
        "END as State,\n",
        "count(*) as freq\n",
        "from df_KDDCup\n",
        "where guest_login != '1'\n",
        "group By Protocal,State\n",
        "order by Protocal Desc\n",
        "\"\"\"\n",
        "spark.sql(sql_query).show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkQU9wOcRsZI",
        "outputId": "c7518ab0-fae0-4f48-ae7d-75d53ea86328"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+----+\n",
            "|            Protocal| State|freq|\n",
            "+--------------------+------+----+\n",
            "|�����l�a<w�����`�...|attack|   1|\n",
            "+--------------------+------+----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1I5KErq6Rsa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3\n",
        "Apply some Descriptive Satistics on numerical Data"
      ],
      "metadata": {
        "id": "v7H0QYJ8WtiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "summary = df.select(mean(df.src_bytes).alias(\"Avg\"),\n",
        "                    stddev(df.src_bytes).alias(\"std\"),\n",
        "                    min(df.src_bytes).alias(\"min\"),\n",
        "                    max(df.src_bytes).alias(\"max\"),\n",
        "                    skewness(df.src_bytes).alias(\"skewness\"))\n",
        "summary.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed70t9e3Rsed",
        "outputId": "00f555d4-3c8d-4fd7-e249-860a5246ca4b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------+---+-------+-------------------+\n",
            "|              Avg|              std|min|    max|           skewness|\n",
            "+-----------------+-----------------+---+-------+-------------------+\n",
            "|5.538461538461538|2.106157030208678|   |󩔏�����|-0.4179375208829422|\n",
            "+-----------------+-----------------+---+-------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groups = df.groupBy(\"Protocol\")\n",
        "groups.agg({'src_bytes':'mean'}).show()"
      ],
      "metadata": {
        "id": "KR_MZVIfW4ZR"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MkhgLn--Y_PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions 4"
      ],
      "metadata": {
        "id": "62ZRXRy8ZpfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sql_query = \"\"\"\n",
        "\n",
        "select protocol from df_KDDCup\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Pkb7CAb9Zrrk"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k9VKhR0RZ8nT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}