{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32dab2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e5079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/04 17:21:06 WARN Utils: Your hostname, ZSCHN01LP0253L resolves to a loopback address: 127.0.1.1; using 192.168.1.5 instead (on interface wlp0s20f3)\n",
      "23/04/04 17:21:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/04 17:21:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/04 17:21:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.5:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0139465670>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Spark Session (It will executed in the Local Not in the Master Node)\n",
    "spark=SparkSession.builder.master(\"local[*]\").appName(\"demo\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac203bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EMPLOYEE_ID: integer (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- EMAIL: string (nullable = true)\n",
      " |-- PHONE_NUMBER: string (nullable = true)\n",
      " |-- HIRE_DATE: string (nullable = true)\n",
      " |-- JOB_ID: string (nullable = true)\n",
      " |-- SALARY: integer (nullable = true)\n",
      " |-- COMMISSION_PCT: string (nullable = true)\n",
      " |-- MANAGER_ID: string (nullable = true)\n",
      " |-- DEPARTMENT_ID: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf = spark.read.option(\"header\",True).option(\"inferSchema\",True).csv(\"../../Spark-main/employees.csv\")\n",
    "empDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba0a5d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+----------+-----------+\n",
      "|DEPARTMENT_ID|DEPARTMENT_NAME|MANAGER_ID|LOCATION_ID|\n",
      "+-------------+---------------+----------+-----------+\n",
      "|           10| Administration|       200|       1700|\n",
      "|           20|      Marketing|       201|       1800|\n",
      "|           30|     Purchasing|       114|       1700|\n",
      "|           40|Human Resources|       203|       2400|\n",
      "|           50|       Shipping|       121|       1500|\n",
      "+-------------+---------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deptDf = spark.read.option(\"header\",True).option(\"inferSchema\",True).csv(\"../../Spark-main/departments.csv\")\n",
    "deptDf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744fae4c",
   "metadata": {},
   "source": [
    "### UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e40041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n",
      "+-----------+----------+---------+--------------------+-------------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|<lambda>(FIRST_NAME)|<lambda>(LAST_NAME)|\n",
      "+-----------+----------+---------+--------------------+-------------------+\n",
      "|        198|    Donald| OConnell|              DONALD|           OCONNELL|\n",
      "|        199|   Douglas|    Grant|             DOUGLAS|              GRANT|\n",
      "|        200|  Jennifer|   Whalen|            JENNIFER|             WHALEN|\n",
      "|        201|   Michael|Hartstein|             MICHAEL|          HARTSTEIN|\n",
      "|        202|       Pat|      Fay|                 PAT|                FAY|\n",
      "|        203|     Susan|   Mavris|               SUSAN|             MAVRIS|\n",
      "|        204|   Hermann|     Baer|             HERMANN|               BAER|\n",
      "|        205|   Shelley|  Higgins|             SHELLEY|            HIGGINS|\n",
      "|        206|   William|    Gietz|             WILLIAM|              GIETZ|\n",
      "|        100|    Steven|     King|              STEVEN|               KING|\n",
      "|        101|     Neena|  Kochhar|               NEENA|            KOCHHAR|\n",
      "|        102|       Lex|  De Haan|                 LEX|            DE HAAN|\n",
      "|        103| Alexander|   Hunold|           ALEXANDER|             HUNOLD|\n",
      "|        104|     Bruce|    Ernst|               BRUCE|              ERNST|\n",
      "|        105|     David|   Austin|               DAVID|             AUSTIN|\n",
      "|        106|     Valli|Pataballa|               VALLI|          PATABALLA|\n",
      "|        107|     Diana|  Lorentz|               DIANA|            LORENTZ|\n",
      "|        108|     Nancy|Greenberg|               NANCY|          GREENBERG|\n",
      "|        109|    Daniel|   Faviet|              DANIEL|             FAVIET|\n",
      "|        110|      John|     Chen|                JOHN|               CHEN|\n",
      "+-----------+----------+---------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf,col\n",
    "\n",
    "def upperCase(in_str):\n",
    "    out_str = in_str.upper()\n",
    "    return out_str\n",
    "\n",
    "print(upperCase(\"hello\"))\n",
    "upperCaseUDF = udf(lambda z : upperCase(z) , StringType())\n",
    "empDf.select(col(\"EMPLOYEE_ID\") , col(\"FIRST_NAME\"), col(\"LAST_NAME\"), upperCaseUDF(col(\"FIRST_NAME\")), upperCaseUDF(col(\"LAST_NAME\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef957f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=StringType())\n",
    "def upperCaseNew(in_str):\n",
    "    out_str = in_str.upper()\n",
    "    return out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052d0271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------------------------+-----------------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|upperCaseNew(FIRST_NAME)|upperCaseNew(LAST_NAME)|\n",
      "+-----------+----------+---------+------------------------+-----------------------+\n",
      "|        198|    Donald| OConnell|                  DONALD|               OCONNELL|\n",
      "|        199|   Douglas|    Grant|                 DOUGLAS|                  GRANT|\n",
      "|        200|  Jennifer|   Whalen|                JENNIFER|                 WHALEN|\n",
      "|        201|   Michael|Hartstein|                 MICHAEL|              HARTSTEIN|\n",
      "|        202|       Pat|      Fay|                     PAT|                    FAY|\n",
      "|        203|     Susan|   Mavris|                   SUSAN|                 MAVRIS|\n",
      "|        204|   Hermann|     Baer|                 HERMANN|                   BAER|\n",
      "|        205|   Shelley|  Higgins|                 SHELLEY|                HIGGINS|\n",
      "|        206|   William|    Gietz|                 WILLIAM|                  GIETZ|\n",
      "|        100|    Steven|     King|                  STEVEN|                   KING|\n",
      "|        101|     Neena|  Kochhar|                   NEENA|                KOCHHAR|\n",
      "|        102|       Lex|  De Haan|                     LEX|                DE HAAN|\n",
      "|        103| Alexander|   Hunold|               ALEXANDER|                 HUNOLD|\n",
      "|        104|     Bruce|    Ernst|                   BRUCE|                  ERNST|\n",
      "|        105|     David|   Austin|                   DAVID|                 AUSTIN|\n",
      "|        106|     Valli|Pataballa|                   VALLI|              PATABALLA|\n",
      "|        107|     Diana|  Lorentz|                   DIANA|                LORENTZ|\n",
      "|        108|     Nancy|Greenberg|                   NANCY|              GREENBERG|\n",
      "|        109|    Daniel|   Faviet|                  DANIEL|                 FAVIET|\n",
      "|        110|      John|     Chen|                    JOHN|                   CHEN|\n",
      "+-----------+----------+---------+------------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.select(col(\"EMPLOYEE_ID\") , col(\"FIRST_NAME\"), col(\"LAST_NAME\"), upperCaseNew(col(\"FIRST_NAME\")), upperCaseNew(col(\"LAST_NAME\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa5d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
