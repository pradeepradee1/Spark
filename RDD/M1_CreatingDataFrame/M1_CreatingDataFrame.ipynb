{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTnxD51Hod99",
    "outputId": "12027c28-daa4-4ad6-c26d-3019033d36ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=8ca9b7d22ff43b92e4e614a2423d263a9cbf2c3ce837704a36c7629b032e70a9\n",
      "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
      "Successfully built pyspark\n",
      "Installing collected packages: pyspark\n",
      "Successfully installed pyspark-3.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "z6BmDYD5ofa9",
    "outputId": "a2e07b70-421f-408c-e513-74223c4c8748"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3e10107cb0b1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc4660b6a70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BPc_vb8SotfY",
    "outputId": "7b412fb0-f4d0-484a-c7b6-c4d022218723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------------+\n",
      "| Name|Age|         City|\n",
      "+-----+---+-------------+\n",
      "| John| 28|     New York|\n",
      "|Alice| 34|  Los Angeles|\n",
      "|  Bob| 23|San Francisco|\n",
      "+-----+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"John\", 28, \"New York\"),\n",
    "        (\"Alice\", 34, \"Los Angeles\"),\n",
    "        (\"Bob\", 23, \"San Francisco\")]\n",
    "\n",
    "# Define the schema (column names)\n",
    "columns = [\"Name\", \"Age\", \"City\"]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhDY70GLpyi7",
    "outputId": "05aff578-bc7a-4675-bd82-692808aa07c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q76GMAkOsRVm",
    "outputId": "902e205e-b6bf-44d4-a7d5-d04bba683b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows=  5\n",
      "Columns=  5\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows= \",df.count())\n",
    "print(\"Columns= \",len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2U_26lFjp3R2"
   },
   "outputs": [],
   "source": [
    "#Type 2\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMBZX4EQqQLa",
    "outputId": "30f81436-e2bf-463a-fd44-85f2a2bfa2b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+---+------+\n",
      "|firstname|middlename|lastname| id|gender|\n",
      "+---------+----------+--------+---+------+\n",
      "|    Berry|          |   Allen|  1|     M|\n",
      "|   Oliver|     Queen|        |  2|     M|\n",
      "|   Robert|          |Williams|  3|     M|\n",
      "|     Tony|          |   Stark|  4|     F|\n",
      "|    Rajiv|      Mary|   Kumar|  5|     F|\n",
      "+---------+----------+--------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person_list = [(\"Berry\",\"\",\"Allen\",1,\"M\"),\n",
    "        (\"Oliver\",\"Queen\",\"\",2,\"M\"),\n",
    "        (\"Robert\",\"\",\"Williams\",3,\"M\"),\n",
    "        (\"Tony\",\"\",\"Stark\",4,\"F\"),\n",
    "        (\"Rajiv\",\"Mary\",\"Kumar\",5,\"F\")\n",
    "]\n",
    "\n",
    "#Creating The Schema For the Dataset\n",
    "schema = StructType([ \\\n",
    "        StructField(\"firstname\",StringType(),True), \\\n",
    "        StructField(\"middlename\",StringType(),True), \\\n",
    "        StructField(\"lastname\",StringType(),True), \\\n",
    "        StructField(\"id\", IntegerType(), True),\\\n",
    "        StructField(\"gender\", StringType(), True)])\n",
    "\n",
    "#Creating Spark DataFrame\n",
    "df = spark.createDataFrame(data=person_list,schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwdMB1dcqbtJ",
    "outputId": "b40bef9f-198f-4fa7-86ea-193bc86dcc18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sZvf4zCqmxn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
